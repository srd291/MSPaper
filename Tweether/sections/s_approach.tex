\section{Approach}

Implementing Tweether has multiple steps which are composed of individual and interconnected components. We use both the weather data and the Twitter data in our study (Section~\ref{sec:dataset}). Based on the clustering result of the weather data (Section~\ref{sec:clust}) and the sentiment prediction of each tweet (Section~\ref{sec:senti}), we correlate these two entities (Section~\ref{sec:corr}). We represent the derived correlation as a graph, and use line bundling for visualization (Section \ref{sec:line}). In addition, we also predict the sentiment for future times (Section~\ref{sec:pred}). The steps are illustrated in Figure \ref{fig:steps}.


%We describe the different data sets we used in Section~\ref{sec:dataset}, how we clustered the weather data in Section \ref{sec:clust}, and how we predicted the sentiment of each tweet in Section \ref{sec:senti}. Correlating the two entities of this work is described in Section \ref{sec:corr}, and the implementation of the line bundling to indicate the correlation in Section \ref{sec:line}.  In addition to these items, we try to implement a prediction  for the sentiment for future times which we discuss in Section \ref{sec:pred}. The steps are illustrated in Figure \ref{fig:steps}.

Tweether in its simplest form takes tweets and assigns a sentiment value which is then correlated to the nearest weather cluster. Each tweet is aligned to the map according to its geographic location. The current hour visualization and the prediction visualization have the same user interface. We embrace the natural link of weather up in the sky to the tweets down on earth to implement our visualization (Section~\ref{sec:vis}). After we implement each of the necessary steps we can clearly see how the visualization adopts a layered implementation which effectively highlights the correlation of weather and emotion in space-time.
%----------------------------------------------------------
\begin{figure}[htb]
 \centering
 \includegraphics[scale=0.1]{steps}
 \caption{The major steps of Tweether}
 \label{fig:steps}
\end{figure}
%----------------------------------------------------------

\subsection{Data Sets}
\label{sec:dataset}

We use two main data sets with respect to weather and Twitter in this work. The weather data set is generated from a climate simulation using Weather Research and Forecasting (WRF) Model~\cite{Michalakes2004}. %from the Holland Computing Center (HCC).
The data provides hourly forecasts with up to 72 hours in the future. Each WRF file contains multiple variables in regards to weather (i.e., temperature, precipitation, wind speed, etc.). For this visualization, we choose to focus on the surface skin temperature (TSK) variable. Each TSK file is represented via a 2D array %$34 \times 24$
covering a regular geographic region. In this work, we use the WRF data that geographically corresponds to the state of Nebraska.
%The WRF file geographically corresponds to Nebraska and surrounding states as seen in Figure \ref{fig:maps}.

The Twitter data set contains the live data feed from Twitter users throughout Nebraska and is synchronized with the weather data. Only users that have opted-in to turn on the feature of Tweeting With Location are selected. In addition, because Nebraska has a fairly low population with most of the land being barren, only the most populous cities are chosen. These cities include Omaha, Lincoln, Grand Island, Kearney, Fremont, North Platte, Norfolk, Columbus, and Scottsbluff. We use a geographic filtering process to select these cities. The Twitter data is stored in JSON format where we need to extract the coordinates of each tweet and the tweet itself. Due to some cities being on the border of Nebraska such as Omaha, the Twitter data needs to have a second filter which removes any tweets that do not have any relation with Nebraska.

%----------------------------------------------------------
%\begin{figure}[htp]
%  \centering
%  \subfigure[Map showing surrounding states with counties]{\includegraphics[scale=0.17]{mapBefore}}\quad
%  \subfigure[Map reduced to show prominance to Nebraska]{\includegraphics[scale=0.14]{mapAfter}}
%\caption{Nebraska map before and after}
%\label{fig:maps}
%\end{figure}
%----------------------------------------------------------

\subsection{Weather Clustering}
\label{sec:clust}

We use clustering to extract different weather patterns from the WRF data and identify their geographic coverage. The clustering of weather differs depending on if looking at the current hour or the predicted values for the next 72 hours. For the current hour of weather, we use the k-means clustering algorithm. %Since we don't need to worry about the future at the current state nothing additional is added to the algorithm.
For the predicted weather, we use the dynamic time warping (DTW) algorithm~\cite{salvador2007toward}.

We use the k-means clustering algorithm to partition each TSK time step into a set of clusters. Some clusters can be dispersed, resulting in random patterns or outliers. These outliers are removed because we assume that moods are affected mostly by comparably dominated weather patterns, and the outliers are small in space and can be changed dynamically in time. To remove outliers, we use a filtering process based on the number of data points in each cluster. If there exists a cluster which has less than one percent of the overall number of clustered elements, this cluster is removed and the data points which belong to a cluster are clustered again. This process is continued until there is no cluster which has less than one percent of the overall cluster count. %In this study, we choose five clusters that gives us good results.



For the forecasted weather, a modified k-means algorithm was used originally. Since k-means isn't very robust towards outliers due to adding a square weight on the value, we used dynamic time warping to measure the similarity between two hours.

To smooth any randomness, connectivity is used to determine the percentage of surrounding elements with the same cluster value as the central element. If at least five out of 8 neighbors have the same value then this cluster is kept, otherwise the data point is removed. This method is repeated four times to ensure smooth clusters. The number of times to be repeated was chosen due to it creating the most smooth outcome amongst the majority of 73 hours.

\subsection{Semantic}
\label{sec:senti}

Each tweet can contain different attributes other than plain sentences. Due to each tweet being limited to 140 characters the majority of users tend to use abbreviations, neologisms (i.e. noob, troll), acronyms hashtags, emoticons, and URL's. Abbreviations, acronyms, and neologisms are taken into account for training our classifier, however, a few items are filtered from certain tweets. The filtering process removes  emoticons, URL's, usernames, and hashtags. In some situations, it is known that hashtags can provide instant insight as to what the users are feeling.[6] However, we feel with most hashtags that we encountered they contained useless text or sentences for tags instead of keywords.

A Naive Bayes classifier is used to determine the sentiment of tweets.
Using Robert Plutchik's theory, it states that there are eight basic emotions:
\begin{itemize}
\item negative - fear, anger, sadness, depression, disgust
\item positive - joy, trust, anticipation, surprise
\end{itemize}

These emotions are the basic training portion of the classification of tweets. The synonyms for each category are taken into account and this sets up the basic foundation for the tweet classifier.

Other than acronyms we also need to take into account profanity. The use of profanity in social media is very high and it may lead to a positive or negative emotion depending on the situation. To take into account how profanity is used in sentences, tweets were polled to see how these words were used. Using these tweets to train the classifier gave a pretty high accuracy rate in regards to profanity. In the beginning we tried to remove any tweet with profanity, however, this drastically lowered our tweet count. We then tried to remove occurrences of profanity in the tweet and use the remaining words as a judge of emotion. This worked in a few cases however for the most part the we believed that profanity gave insight to negative moods so we decided to take into account profanity.

Due to tweets using abbreviations and incomplete sentences, sentiment calculation is a nontrivial task. The classifier is trained using around 10,000 tweets, where each tweet was given a positive and negative score, and there were rare occurrences of duplicate tweet, and it was made sure that there was an equal portion of positive and negative tweets in regards to words where sentiment could go either way.


\subsection{Correlation}
\label{sec:corr}

The correlation between each tweet and the cluster above is represented by a one to one mapping. As we see in Figure \ref{fig:clusters}(a), if there is a natural link then the mapping is pure. In situations where there isn't a direct link to any of the weather clusters the nearest cluster is used.

Other than the natural link between the primary cluster and the tweet we explore similarity of connections to other clusters regardless of the sentiment it may correspond to. This correlation is only available for the current hour. For each tweet, we use the top two relations to other clusters which we deem the secondary and tertiary clusters. Using the Pearson product-moment correlation coefficient, we determine the similarity of each tweet cluster to other clusters.(1) With a correlation value closer to one we keep the sentiment expressed in the primary cluster, however in the case of a correlation value closer to negative one we swap the sentiment expressed in the primary cluster. We look for the values closest to one or negative one and according to the sign we assign the proper sentiment value. Figure \ref{fig:clusters}(b and c) show the secondary and tertiary cluster.

\begin{equation}
\label{eq:pearson}
\rho_{X,Y}=\frac{cov(X,Y)}{\sigma_{X}\sigma_{Y}}
\end{equation}

cov is the covariance and $\sigma_{X}$ is the standard deviation of X \\

We use the location of the tweet and the temperature at that point to determine the best correlation value to all other points in other clusters. Disregarding the primary cluster we choose to focus on the mapping to the other clusters to indicate what other clusters the tweet could map to. In most cases, the secondary and tertiary mapping have the same sentiment since the best fit is a cluster close by with a similar temperature.


\begin{figure}[htp]
  \centering
  \subfigure[Primary Cluster]{\includegraphics[scale=0.09]{blurBefore}}\quad
  \subfigure[Secondary Cluster]{\includegraphics[scale=0.09]{blurAfter}}\quad
  \subfigure[Tertiary Cluster]{\includegraphics[scale=0.09]{blurAfter}}
\caption{Clustering of the weather. In this hour, we see five different clusters. The blue cluster is seen in three different locations.}
\label{fig:clusters}
\end{figure}

\subsection{Line Bundling}
\label{sec:line}

We adopt FDEB~\cite{holten2009force} to visualize the graph of correlation. We bundle the related edges with high compatibilities, and iteratively subdivide the edges to generate smooth curves with coherent shapes. This approach can effectively reduce visual clutter in 3D.

The original paper of FDEB~\cite{holten2009force} proposed four criteria, angle, scale, position, and visibility, for edge compatibility measures. In our design, as the edges are mostly oriented along the vertical direction between cloud and ground, the variation in angle or scale is relatively marginal compared to a general graph. In addition, as we display the edges in 3D, the visibility of an edge can be changed from different views. Therefore, only position (i.e., distance between midpoints of edges) is considered for computing edge compatibility in our design.

Similar to FDEB, we use an iterative simulation to refine the bundling. The simulation starts with $P_0$ subdivision points for each edge, and then performs $C$ simulation cycles. During each cycle, a specific number of iteration steps $I$ is conducted to move the subdivision points to reach an equilibrium between forces. The number of iteration steps during the first cycle is $I_0$. After performing a cycle, the number of subdivision points is doubled to smoothen the edges, and the number of iteration steps $I$ is decreased by a factor $R$. We found that a configuration of $P_0=1$, $C=6$, $I_0=50$, and $R=\frac{2}{3}$ leads to appropriate results in our design.


\subsection{Prediction}
\label{sec:pred}

Predicting the future is mostly based on facts. We have at our disposal the current mood and the current temperature, all of the previous days tweets and the temperatures for each hour and the predicted temperature for each hour for the next two days. Using these facts, we try to determine what the sentiment at each location which people are tweeting from currently will be for the next two days.

Determining the mood of the current locations up to 72 hours in the future is a nontrivial task. Our prediction technique is completely based on the current hour and the previous day. We choose not to use data from earlier times since the trends today are definitely not the same a year ago let alone a month ago. In addition to this, we should state that the weather is unpredictable for the state of Nebraska.

We started with the most rudimentary implementation, by solely comparing which number is closer by simply comparing the difference. If the current temperature is closer to the predicted temperature then the sentiment for the current hour is used to show the prediction. If the sentiment of the hour we are trying to pick has a closer temperature to the same hour of the previous day then we use the sentiment from the previous day.

Seeing that the previously stated implementation was very crude, we tried a different method. Depending on the hour we are trying to predict we state that if the current hour is at most five hours ago we will place a higher weight on using the current hours values, however when going past five hours we place more weight on the previous days values, where the further we are from the current hour the less weight it plays. Using this method we take the sentiment based on the percentage of the weight.

The final method we try is a combination of above methods. Where we first determine the closest temperature value to the hour we are trying to predict the sentiment. Then based on the difference we determine the weight the two different sentiment sets place \eqref{eq:w}. As we see in \eqref{eq:p} X and Y represent the current temperature and the previous day's temperature respectively, and Z represents the temperature of the hour that we are trying to predict. The number of good and bad sentiment lines is calculated in \eqref{eq:gb}, where $G$ and $B$ represent the number good and bad tweets predicted by using the good and bad tweets of X and Y. The details regarding how well the different methods performed will be seen later on in the case studies.\\

$p_1$ and $p_2$ represent the difference between the temperatures
\begin{equation} \label{eq:p} p_{1}=\left | Z-X \right |	\qquad p_{2}=\left | Z-Y \right |	 \end{equation}

$w_1$ and $w_2$ represent weight of the temperatures
\begin{equation} \label{eq:w} w_{1}=\frac{p_{2}}{p_{1}+p_{2}} 	\qquad w_{2}=\frac{p_{1}}{p_{1}+p_{2}}   \end{equation}

$g_x, g_y, b_x,$ and $b_y$ represent the amount of good and bad tweets in X and Y
\begin{equation} \label{eq:gb}  G = g_{x}w_{1} + g_{y}w_{2}	\qquad B = b_{x}w_{1} + b_{y}w_{2}	 \end{equation}


